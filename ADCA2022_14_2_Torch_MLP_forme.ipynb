{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dewoZWT6i2az"
      },
      "source": [
        "# データ解析特論 2022年度水曜２限\n",
        "\n",
        "# 第14回 その2 Torch で MLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4zpM8Im8E1Ec"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, random_split, DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fhmNNwRE-7i"
      },
      "source": [
        "## MNIST\n",
        "\n",
        "`sklearn.datasets` の MNIST を使う．\n",
        "解像度の小さいバージョンで学習がしやすいお手軽版．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "5wB8nAdmE4ru",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d264bb1-855a-4d14-b320-5ca37d88bf20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1797, 64)\n",
            "(1797,)\n"
          ]
        }
      ],
      "source": [
        "# MNIST データの読み込み\n",
        "digits = datasets.load_digits()\n",
        "\n",
        "# 画像データを配列に変換\n",
        "X = digits.data\n",
        "print(X.shape)\n",
        "\n",
        "# 画像データのピクセル値の範囲を調べる\n",
        "\n",
        "\n",
        "# X の値域を [0,1] にしておく\n",
        "X /= np.max(X)\n",
        "\n",
        "# 画像データに対するラベル\n",
        "Y = digits.target\n",
        "print(Y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rx75d11Ci2a4"
      },
      "source": [
        "## PyTorch\n",
        "\n",
        "### device の設定"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLx3S4-oFPIy",
        "outputId": "2841d3fc-b772-4393-f638-405478d4b533"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version 1.13.1+cu116\n",
            "True\n",
            "True\n",
            "cuda\n"
          ]
        }
      ],
      "source": [
        "print('PyTorch version %s'%torch.__version__ )\n",
        "\n",
        "print('%s'%torch.backends.cuda.is_built())\n",
        "print('%s'%torch.cuda.is_available())\n",
        "\n",
        "# print('%s'%torch.backends.mps.is_built())\n",
        "# print('%s'%torch.backends.mps.is_available())\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = 'cuda'\n",
        "elif torch.backends.mps.is_available():\n",
        "    device = 'mps'\n",
        "else:\n",
        "    device = 'cpu'\n",
        "\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PI3eQDYwi2a4"
      },
      "source": [
        "### パラメータ設定"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-gcsevTLbpgT"
      },
      "outputs": [],
      "source": [
        "# 画像サイズ\n",
        "IMAGE_SIZE = (8, 8)\n",
        "\n",
        "# Loarder のバッチサイズ\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# 何コア使ってデータを読むか\n",
        "NUM_WORKERS = 2\n",
        "\n",
        "# 学習の反復回数\n",
        "NUM_EPOCHS = 300\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qn8RU-Xri2a5"
      },
      "source": [
        "## データ準備\n",
        "\n",
        "### データを PyTorch 用に変換"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqafDaKkFbRE",
        "outputId": "ff14e1ed-d3d0-4945-f771-e82fe4f07d2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1797, 10])\n",
            "1198 599\n"
          ]
        }
      ],
      "source": [
        "# Torch のの Tensor 型に変換\n",
        "Xtensor = torch.tensor(X, dtype=torch.float32)\n",
        "Ytensor = torch.tensor(Y, dtype=torch.int64)\n",
        "\n",
        "# label を 1-hot vector \n",
        "Ytensor = F.one_hot(Ytensor, num_classes=len(digits.target_names)).float()\n",
        "print(Ytensor.shape)\n",
        "\n",
        "# Torch の Dataset\n",
        "Dataset = TensorDataset(Xtensor, Ytensor)\n",
        "\n",
        "# Dataset を train-test split\n",
        "train_size = len(Dataset)*2//3\n",
        "test_size = len(Dataset) - train_size\n",
        "train_Dataset, test_Dataset = random_split(Dataset, [train_size, test_size])\n",
        "print(len(train_Dataset), len(test_Dataset))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7J0HHS3vi2a6"
      },
      "source": [
        "### DataLoader の設定"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "86OP3a4wMRym"
      },
      "outputs": [],
      "source": [
        "# DataLoader (iterable) を構成\n",
        "train_loader = DataLoader(dataset=train_Dataset, batch_size=BATCH_SIZE,\n",
        "                          shuffle=True, num_workers=NUM_WORKERS)\n",
        "test_loader = DataLoader(dataset=test_Dataset, batch_size=BATCH_SIZE,\n",
        "                          shuffle=True, num_workers=NUM_WORKERS)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3wMf-jkg3RQ4"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txjSjIuhi2a7"
      },
      "source": [
        "## モデル構成\n",
        "\n",
        "ここでは隠れ層を2層持つ MLP を構成しよう．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "wHC2jX1aR5EI"
      },
      "outputs": [],
      "source": [
        "# 多層パーセプトロンのノード数\n",
        "d_in = 64\n",
        "d_h1 = 32\n",
        "d_h2 = 16\n",
        "d_out = 10 # Y を 1-hot vector にしておけばしておけば d_out = 10\n",
        "\n",
        "# モデルのクラス\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(d_in, d_h1)\n",
        "        self.fc2 = nn.Linear(d_h1, d_h2)\n",
        "        self.out = nn.Linear(d_h2, d_out)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.out(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# # モデルのインスタンス化\n",
        "# model = Model().to(device)\n",
        "# print(model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fal8b5Emi2a8"
      },
      "source": [
        "## 学習用関数\n",
        "\n",
        "Torch では 1 epoch 学習する関数を設定して反復させる形態をとる．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "QYSqRWeLVoyI"
      },
      "outputs": [],
      "source": [
        "def train(model, train_Loader, criterion, optimizer, device='cpu'):\n",
        "    # loss と 1 epoch で用いたデータのサンプルサイズ用の変数を初期化\n",
        "    train_loss = 0.0\n",
        "    n_train = 0\n",
        "    # model 学習モードに設定\n",
        "    model.train()\n",
        "    \n",
        "    # train_Loader からデータを取り出して loss と勾配を計算\n",
        "    for Xs, Ys in train_Loader:\n",
        "        # ミニバッチのサンプルサイズ\n",
        "        n_train += len(Ys)\n",
        "        \n",
        "        # データを device に転送\n",
        "        Xs, Ys = Xs.to(device), Ys.to(device)\n",
        "        \n",
        "        # ミニバッチごとに勾配はリセット\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # model での出力を計算\n",
        "        outputs = model(Xs)\n",
        "        \n",
        "        # loss を計算\n",
        "        loss = criterion(outputs, Ys)\n",
        "        \n",
        "        # 誤差逆伝播\n",
        "        loss.backward()\n",
        "        \n",
        "        # ネットワークのパラメータを更新\n",
        "        optimizer.step()\n",
        "        \n",
        "        # loss の総和の計算のために足しておく\n",
        "        train_loss += loss.item()\n",
        "        \n",
        "    # 1 epoch に用いたサンプルサイズで損失を平均\n",
        "    train_loss = train_loss / n_train\n",
        "    \n",
        "    # return\n",
        "    return train_loss\n",
        "\n",
        "def test(model, test_Loader, criterion, optimizer, device='cpu'):\n",
        "    \n",
        "    # loss と 1 epoch で用いたデータのサンプルサイズ用の変数を初期化\n",
        "    test_loss = 0.0\n",
        "    n_test = 0\n",
        "\n",
        "    # model を学習できない状態にする\n",
        "    model.eval()\n",
        "\n",
        "    # test_Loader からデータを取り出して loss を計算．勾配は計算しない\n",
        "    with torch.no_grad():\n",
        "        for Xs, Ys in test_Loader:\n",
        "            # ミニバッチのサンプルサイズ\n",
        "            n_test += len(Ys)\n",
        "            \n",
        "            # データを device に転送\n",
        "            Xs, Ys = Xs.to(device), Ys.to(device)\n",
        "            \n",
        "            # model での出力を計算 \n",
        "            outputs = model(Xs)\n",
        "            \n",
        "            # loss を計算\n",
        "            loss = criterion(outputs, Ys)\n",
        "            \n",
        "            # loss の総和の計算のために足しておく\n",
        "            test_loss += loss.item()\n",
        "        \n",
        "        # 1 epoch に用いたサンプルサイズで損失を平均   \n",
        "        test_loss = test_loss / n_test\n",
        "\n",
        "    return test_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5f4aGrT-i2a9"
      },
      "source": [
        "## 学習方法の設定"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcb6f230R4_O",
        "outputId": "d5a9b1b0-032b-439f-fcfd-0cb7c7252553"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model(\n",
            "  (fc1): Linear(in_features=64, out_features=32, bias=True)\n",
            "  (fc2): Linear(in_features=32, out_features=16, bias=True)\n",
            "  (out): Linear(in_features=16, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# モデルのインスタンス化\n",
        "model = Model().to(device)\n",
        "print(model)\n",
        "\n",
        "# 損失関数の設定\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 最適化手法を設定\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwJABKFhi2a-"
      },
      "source": [
        "## では学習！"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jF-n9pxVotC",
        "outputId": "d4c9832f-b425-4f11-dca0-fec79e10ccd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 10] train loss = 0.00180 | test loss = 0.00410\n",
            "[Epoch 20] train loss = 0.00170 | test loss = 0.00404\n",
            "[Epoch 30] train loss = 0.00160 | test loss = 0.00423\n",
            "[Epoch 40] train loss = 0.00153 | test loss = 0.00393\n",
            "[Epoch 50] train loss = 0.00145 | test loss = 0.00394\n",
            "[Epoch 60] train loss = 0.00136 | test loss = 0.00403\n",
            "[Epoch 70] train loss = 0.00127 | test loss = 0.00389\n",
            "[Epoch 80] train loss = 0.00121 | test loss = 0.00395\n",
            "[Epoch 90] train loss = 0.00120 | test loss = 0.00394\n",
            "[Epoch 100] train loss = 0.00109 | test loss = 0.00397\n",
            "[Epoch 110] train loss = 0.00104 | test loss = 0.00389\n",
            "[Epoch 120] train loss = 0.00098 | test loss = 0.00392\n",
            "[Epoch 130] train loss = 0.00094 | test loss = 0.00395\n",
            "[Epoch 140] train loss = 0.00092 | test loss = 0.00385\n",
            "[Epoch 150] train loss = 0.00087 | test loss = 0.00385\n",
            "[Epoch 160] train loss = 0.00081 | test loss = 0.00393\n",
            "[Epoch 170] train loss = 0.00079 | test loss = 0.00381\n",
            "[Epoch 180] train loss = 0.00076 | test loss = 0.00390\n",
            "[Epoch 190] train loss = 0.00072 | test loss = 0.00409\n",
            "[Epoch 200] train loss = 0.00070 | test loss = 0.00385\n",
            "[Epoch 210] train loss = 0.00067 | test loss = 0.00393\n",
            "[Epoch 220] train loss = 0.00064 | test loss = 0.00391\n",
            "[Epoch 230] train loss = 0.00061 | test loss = 0.00390\n",
            "[Epoch 240] train loss = 0.00060 | test loss = 0.00390\n",
            "[Epoch 250] train loss = 0.00058 | test loss = 0.00402\n",
            "[Epoch 260] train loss = 0.00055 | test loss = 0.00402\n",
            "[Epoch 270] train loss = 0.00053 | test loss = 0.00396\n",
            "[Epoch 280] train loss = 0.00051 | test loss = 0.00394\n",
            "[Epoch 290] train loss = 0.00049 | test loss = 0.00399\n",
            "[Epoch 300] train loss = 0.00048 | test loss = 0.00400\n",
            "CPU times: user 34.1 s, sys: 35 s, total: 1min 9s\n",
            "Wall time: 1min 44s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# 1 epoch ごとの loss を格納するリスト\n",
        "train_loss_list = []\n",
        "test_loss_list = []\n",
        "\n",
        "# 学習：NUM_EPOCH 反復\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    \n",
        "    # 学習\n",
        "    trainloss = train(model, train_loader, criterion, optimizer, device=device)\n",
        "    train_loss_list.append(trainloss)\n",
        "    \n",
        "    # test で validation\n",
        "    testloss = test (model, test_loader,  criterion, optimizer, device=device)\n",
        "    test_loss_list.append(testloss)\n",
        "    \n",
        "    # 途中経過の把握のために loss を表示\n",
        "    if (epoch+1)%10 == 0:\n",
        "        print('[Epoch %d] train loss = %.5f | test loss = %.5f'%(epoch+1, trainloss, testloss))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqHsYD79i2a_"
      },
      "source": [
        "## 学習結果の確認\n",
        "\n",
        "### 損失の推移"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uyb00hw2Vonr"
      },
      "outputs": [],
      "source": [
        "# loss の推移の可視化\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voy07CVYi2bA"
      },
      "source": [
        "### 分類の例の図示"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1DJh43I6VoiY"
      },
      "outputs": [],
      "source": [
        "print('training data')\n",
        "\n",
        "\n",
        "print('test data')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-MYINg3i2bB"
      },
      "source": [
        "### 定量評価"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ngkRPgaVocw"
      },
      "outputs": [],
      "source": [
        "# 全データの分類予測を計算\n",
        "\n",
        "\n",
        "# データを device に送る\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffYBr4rJi2bB"
      },
      "source": [
        "### confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-zLaf-qVoRW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hc6AZEkti2bB"
      },
      "source": [
        "### classification report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WiM1usldR48M"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkJnTtNMR40H"
      },
      "source": [
        "## 課題14-2\n",
        "\n",
        "`Model` の `forward` を変えて accuracy を上げてみることを試してみよ．"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znII-nP_jkX2"
      },
      "source": [
        "## 以上"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}