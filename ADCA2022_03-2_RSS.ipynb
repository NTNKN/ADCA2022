{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データ解析特論 2022年度水曜２限\n",
    "\n",
    "# 第3回 その2 残差平方和\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 平方和\n",
    "\n",
    "### 総平方和\n",
    "\n",
    "目的変数 $y_i$ の標本平均 $\\langle y \\rangle$ からの偏差平方和\n",
    "\n",
    "$$\n",
    "S = \\sum_{i=1}^N (y_i - \\langle y \\rangle)^2 \\quad ( = N \\sigma_y^2)\n",
    "$$\n",
    "\n",
    "を<font color=\"#DC143C\">**総平方和** $S$</font> と呼ぶ (TSS)．これは $y_i$ の標本分散 $\\sigma_y^2$ にデータサイズ $N$ を掛けた量であり，目的変数の散らばりを表す．\n",
    "\n",
    "### 回帰平方和\n",
    "\n",
    "回帰モデルによる推定値 $\\hat y_i$ の標本平均 $\\langle \\hat y \\rangle$ からの偏差平方和\n",
    "\n",
    "$$\n",
    "S_{\\rm R} = \\sum_{i=1}^N (\\hat y_i - \\langle \\hat y \\rangle)^2 \\quad ( = N \\sigma_{\\hat y}^2)\n",
    "$$\n",
    "\n",
    "を<font color=\"#DC143C\">**回帰平方和** $S_{\\rm R}$</font> と呼ぶ．これは $\\hat y_i$ の標本分散 $\\sigma_{\\hat y}^2$ にデータサイズ $N$ を掛けた量であり，推定値の散らばりを表す．$y_i$ の散らばりのうち，回帰モデルで説明される部分．\n",
    "\n",
    "### 残差平方和\n",
    "\n",
    "回帰モデルによる回帰残差 $e_i$ の平方和\n",
    "\n",
    "$$\n",
    "S_{\\rm e} = \\sum_{i=1}^N e_i^2 = \\sum_{i=1}^N (y_i - \\hat y_i)^2 \\quad ( = N \\sigma_e^2)\n",
    "$$\n",
    "\n",
    "を<font color=\"#DC143C\">**残差平方和** $S_{\\rm e}$ </font>と呼ぶ (RSS)．これは回帰残差の標本分散 $\\sigma_{e}^2$ にデータサイズ $N$ を掛けた量であり，これが小さいということは回帰モデルがデータによく適合しているということ．$y$ の散らばりのうち，回帰モデルで説明されない部分．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 回帰平方和の別表現\n",
    "\n",
    "線形回帰では $\\langle \\hat y \\rangle = \\langle y \\rangle$ かつ $\\langle \\hat ye \\rangle = 0$ が成り立つので，\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "&\n",
    "\\sum_{i=1}^N (y_i - \\langle y \\rangle) (\\hat y_i - \\langle \\hat y \\rangle)\n",
    "= \\sum_{i=1}^N (y_i - \\hat y_i + \\hat y_i - \\langle \\hat y \\rangle) (\\hat y_i - \\langle \\hat y \\rangle)\n",
    "= \\sum_{i=1}^N (e_i + \\hat y_i - \\langle \\hat y \\rangle) (\\hat y_i - \\langle \\hat y \\rangle)\n",
    "\\\\\n",
    "&\n",
    "\\phantom{\\sum_{i=1}^N (y_i - \\langle y \\rangle) (\\hat y_i - \\langle \\hat y \\rangle)}\n",
    "= \\sum_{i=1}^N e_i \\hat y_i - \\sum_{i=1}^N e_i \\langle \\hat y \\rangle + \\sum_{i=1}^N (\\hat y_i - \\langle \\hat y \\rangle)^2\n",
    "= 0 - 0 + S_{\\rm R}\n",
    "\\\\\n",
    "&\n",
    "\\phantom{\\sum_{i=1}^N (y_i - \\langle y \\rangle) (\\hat y_i - \\langle \\hat y \\rangle)}\n",
    "= S_{\\rm R}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "となる．つまり，回帰平方和をデータサイズで割ると観測値 $y_i$ と $\\hat y_i$ の共分散 $\\sigma_{y\\hat y}$ となる．\n",
    "\n",
    "$$\n",
    "\\sigma_{y\\hat y}\n",
    "= \\langle y \\hat y \\rangle - \\langle y \\rangle \\langle \\hat y \\rangle\n",
    "= \\frac1N \\sum_{i=1}^N (y_i - \\langle y \\rangle) (\\hat y_i - \\langle \\hat y \\rangle) = \\frac1N S_{\\rm R}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 平方和の分解\n",
    "\n",
    "線形回帰の場合は $\\langle \\hat y \\rangle = \\langle y \\rangle$ が成り立つため，\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "&\n",
    "S \n",
    "= \\sum_{i=1}^N (y_i - \\langle y \\rangle)^2\n",
    "= \\sum_{i=1}^N (y_i - \\hat y_i + \\hat y_i - \\langle y \\rangle)^2\n",
    "= \\sum_{i=1}^N (e_i + \\hat y_i - \\langle \\hat y \\rangle)^2\n",
    "= \\sum_{i=1}^N \\left\\{ e_i^2 + 2 e_i (\\hat y_i - \\langle \\hat y \\rangle) + (\\hat y_i - \\langle \\hat y \\rangle)^2 \\right\\}\n",
    "\\\\\n",
    "&\n",
    "\\phantom{S}\n",
    "= \\sum_{i=1}^N e_i^2 + 2 \\sum_{i=1}^N e_i (\\hat y_i - \\langle \\hat y \\rangle) + \\sum_{i=1}^N (\\hat y_i - \\langle \\hat y \\rangle)^2 \n",
    "= S_{\\rm e} + 2 \\sum_{i=1}^N e_i (\\hat y_i - \\langle \\hat y \\rangle) + S_{\\rm R}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "と平方和を展開する．さらに $\\langle e \\rangle = 0$, $\\langle xe \\rangle = 0$ より，\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^N e_i (\\hat y_i - \\langle \\hat y \\rangle) \n",
    "= \\sum_{i=1}^N e_i (\\hat b_0 + \\hat b_1 x_i - \\langle \\hat y \\rangle) \n",
    "= (\\hat b_0 - \\langle \\hat y \\rangle) \\sum_{i=1}^N e_i + \\hat b_1 \\sum_{i=1}^N e_i x_i\n",
    "= 0\n",
    "$$\n",
    "\n",
    "となることがわかるので，総平方和は\n",
    "\n",
    "$$\n",
    "S = \n",
    "\\underbrace{S_{\\rm R}}_{\\begin{array}{c}\\mbox{回帰で}\\\\\\mbox{表現できる}\\\\\\mbox{散らばり}\\end{array}} \n",
    "+ \\underbrace{S_{\\rm e}}_{\\begin{array}{c}\\mbox{回帰で}\\\\\\mbox{表現できない}\\\\\\mbox{散らばり}\\end{array}}\n",
    "$$\n",
    "\n",
    "と回帰平方和と残差平方和に分解できる．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 平方和の分解の幾何学的意味\n",
    "\n",
    "総平方和は\n",
    "\n",
    "$$\\boldsymbol y - \\langle y \\rangle = \\left( y_1-\\langle y \\rangle, y_2-\\langle y \\rangle, \\ldots, y_N-\\langle y \\rangle \\right)$$ \n",
    "\n",
    "という $N$ 次元ベクトルに対する $N$ 次元ユークリッドノルム（2ノルム）の２乗である．\n",
    "\n",
    "同様に回帰平方和と残差平方和はそれぞれ\n",
    "\n",
    "- 回帰値ベクトル $\\boldsymbol{\\hat y} - \\langle \\hat y \\rangle = \\left( \\hat y_1-\\langle y \\rangle, \\hat y_2-\\langle y \\rangle, \\ldots, \\hat y_N-\\langle y \\rangle \\right)$\n",
    "- 残差ベクトル $\\boldsymbol e = \\left( e_1, e_2, \\ldots, e_N \\right)$\n",
    "\n",
    "の $N$ 次元ユークリッドノルムの２乗である．\n",
    "\n",
    "総平方和の分解ではまず最初に\n",
    "\n",
    "$$\n",
    "\\boldsymbol y - \\langle y \\rangle = \\boldsymbol e + (\\boldsymbol{\\hat y} - \\langle \\hat y \\rangle)\n",
    "$$\n",
    "\n",
    "と2つのベクトルの和に分けたことから，平方和の分解 $S = S_{\\rm R} + S_{\\rm e}$ は\n",
    "\n",
    "$$\n",
    "\\| \\boldsymbol y - \\langle y \\rangle \\|^2 \n",
    "= \\| \\boldsymbol e \\|^2 + \\| (\\boldsymbol{\\hat y} - \\langle \\hat y \\rangle) \\|^2\n",
    "$$\n",
    "\n",
    "というに他ならない（$N$ 次元のピタゴラスの定理）．\n",
    "\n",
    "つまり，目的変数のサンプルの表すベクトルが，回帰方向と残差方向に直交分解できることを意味している．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 平方和の性質\n",
    "\n",
    "基本的に $S>0$ である．\n",
    "\n",
    "もし $S=0$ ならば $\\displaystyle \\sum_{i=1}^N (y_i - \\langle y \\rangle)^2 =0$ ということ．非負の項の和が 0 なので，それぞれの項が 0 でないといけない．\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "&\n",
    "\\sum_{i=1}^N (y_i - \\langle y \\rangle)^2 =0\n",
    "\\quad \\Longrightarrow \\quad \n",
    "(y_i - \\langle y \\rangle)^2 =0 \\quad (i=1, 2, \\ldots, N)\n",
    "\\\\\n",
    "&\n",
    "\\phantom{\\sum_{i=1}^N (y_i - \\langle y \\rangle)^2 =0}\n",
    "\\quad \\Longrightarrow \\quad \n",
    "y_i = \\langle y \\rangle \\quad (i=1, 2, \\ldots, N)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "つまり，目的変数のデータが全て一定ということ．観測データ $(x_i, y_i)$ が $y$ 方向の成分が一定で分布していることを意味している．\n",
    "\n",
    "実際，$x$ と $y$ の共分散 $\\frac{\\sigma_{xy}}{\\sigma_x^2}$ が 0 となることから，回帰変数 $\\hat b_1$ は\n",
    "\n",
    "$$\n",
    "\\hat b_1 = \\frac{\\sigma_{xy}}{\\sigma_x^2} = 0\n",
    "$$\n",
    "\n",
    "となる．回帰モデルは定数関数 $y = \\langle y \\rangle$ で十分で，説明変数 $x$ はいらない．\n",
    "\n",
    "以下では $S>0$ の場合だけを考えることにする．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $S_{\\rm e}=0$ の場合\n",
    "\n",
    "$S_{\\rm e}=0$ のとき，つまり $S = S_{\\rm R} (>0)$ となる場合を考えよう．\n",
    "これは $\\displaystyle \\sum_{i=1}^N e_i^2 =0$ ということ．つまり，全ての回帰残差が $e_i=0$ ということ．これは\n",
    "\n",
    "$$\n",
    "y_i = \\hat y_i = \\hat b_0 + \\hat b_1 x_i\n",
    "$$\n",
    "\n",
    "である．観測されたデータ $(x_i, y_i)$ がもともと直線 $y = \\hat b_0 + \\hat b_1 x$ 上に分布していたことを意味する．なので線形フィッティングは完全にうまくいく．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $S_{\\rm R} = 0$ の場合\n",
    "\n",
    "$S_{\\rm R} = 0$ のとき，つまり $S = S_{\\rm e} (>0)$ となる場合を考えよう．これは $\\displaystyle \\sum_{i=1}^N (\\hat y_i - \\langle \\hat y \\rangle)^2 = 0$ ということなので，$\\hat y_i = \\langle \\hat y \\rangle = \\langle y \\rangle$ $(i=1, 2, \\ldots, N)$ ということ．つまり，回帰直線の傾き $\\hat b_1$ は 0 である．\n",
    "\n",
    "これは $S=0$ の場合と似ているが，実態は異なる．$S>0$ なので，$y_i$ は散らばって分布している．にもかかわらず，$\\hat y_i$ は散らばっていないということは，線形モデルが全く機能しないデータの分布であることを意味している．\n",
    "\n",
    "実際，$\\displaystyle \\hat b_1 = \\frac{\\sigma_{xy}}{\\sigma_x^2} = 0$ なので，分子の $x$ と$y$ の標本共分散が 0 ということ．観測されたデータ上は $x$ と $y$ は無相関（＝線形相関がない）ことを示すため，傾きが 0 でない線形モデルを立てることができない．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 決定係数\n",
    "\n",
    "このように総平方和 $S$ における $S_{\\rm R}$ の割合が大きいほど，線形フィッティングが機能することがわかった．その割合\n",
    "\n",
    "$$\n",
    "R^2 = \\frac{S_{\\rm R}}{S} = 1 - \\frac{S_{\\rm e}}{S}\n",
    "$$\n",
    "\n",
    "を<font color=\"#DC143C\">**決定係数**</font>と呼ぶ．\n",
    "\n",
    "- $R^2$ は 0 から 1 までの値を取る．\n",
    "- $R^2=0$ は $(x_i, y_i)$ が無相関\n",
    "- $R^2=1$ は $(x_i, y_i)$ が同一直線上に乗るデータ\n",
    "\n",
    "$$\n",
    "R^2 = \\frac{S_{\\rm R}}{S} = \\frac{\\sum_{i=1}^N (\\hat y_i - \\langle \\hat y \\rangle)^2}{\\sum_{i=1}^N (y_i - \\langle y \\rangle)^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 観測値と推定値の相関係数\n",
    "\n",
    "観測値 $y_i$ と推定値 $\\hat y_i$ の相関係数 $\\rho_{y\\hat y}$ は決定係数の正の平方根と一致する．\n",
    "\n",
    "$$\n",
    "\\rho_{y\\hat y} \n",
    "= \\frac{\\sigma_{y\\hat y}}{\\sigma_y \\sigma_{\\hat y}}\n",
    "= \\frac{\\langle y \\hat y \\rangle - \\langle y \\rangle \\langle \\hat y \\rangle}{\\sqrt{\\langle y^2 \\rangle - \\langle y \\rangle^2} \\sqrt{\\langle \\hat y^2 \\rangle - \\langle \\hat y \\rangle^2}}\n",
    "= \\frac{\\frac1N S_{\\rm R}}{\\sqrt{\\frac1N S} \\sqrt{\\frac1N S_{\\rm R}} }\n",
    "= \\sqrt{\\frac{S_{\\rm R}}{S}}\n",
    "= \\sqrt{R^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 平方和の自由度\n",
    "\n",
    "総平方和 $S$ の自由度は $N-1$ である．これは標本分散と不偏分散の考え方と全く同じ．\n",
    "\n",
    "残差平方和 $S_{\\rm e}$ の自由度は $N-2$ である．これはサイズ $N$ の残差 $e_i$ $(i=1, 2, \\ldots, N)$ から作られる平方和だが，\n",
    "\n",
    "- $\\langle e \\rangle = 0$\n",
    "- $\\langle xe \\rangle = 0$\n",
    "\n",
    "という2つの拘束条件の下で計算されるため，$N$ より $2$ 小さくなる．\n",
    "\n",
    "これを用いて，決定係数を\n",
    "\n",
    "$$\n",
    "R_f^2 = 1 - \\frac{\\frac{S_{\\rm e}}{N-2}}{\\frac{S}{N-1}}\n",
    "$$\n",
    "\n",
    "と修正することもある．これは自由度調整済み決定係数と呼ばれる．線形単回帰の場合ではほとんど意味をなさないが，説明変数の数が多い重回帰の場合に効力を発揮する．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 線形モデルから生成されるデータから推定されたパラメータの分布\n",
    "\n",
    "以下ではこれまでの仮定に加えて\n",
    "\n",
    "- $y_i = \\beta_0 + \\beta_1 x_i + \\varepsilon_i$ とデータが線形モデルから生成\n",
    "- ランダムネスは $\\varepsilon_i$ のみ \n",
    "- $\\varepsilon_i$ は独立同分布: $\\mathrm E[\\varepsilon_i] = \\mathrm E[\\varepsilon]$, $\\mathrm V[\\varepsilon_i] = \\mathrm V[\\varepsilon]$ （正しくは独立でなくても，無相関でありさえすれば良い）\n",
    "- $\\mathrm E[\\varepsilon] = 0$\n",
    "\n",
    "と与えられるときを考えよう．このときは\n",
    "\n",
    "$$\n",
    "\\langle y \\rangle = \\beta_0 + \\beta_1 \\langle x \\rangle + \\langle \\varepsilon \\rangle\n",
    "$$\n",
    "\n",
    "となる．\n",
    "\n",
    "この仮定の下で $\\hat b_0$ と $\\hat b_1$ の分布を調べてみよう．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\hat b_1$ の分布 \n",
    "\n",
    "$\\displaystyle \\hat b_1 = \\frac{\\sigma_{xy}}{\\sigma_x^2} $ なので\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "&\n",
    "\\sigma_{xy}\n",
    "= \\frac1N \\sum_{i=1}^N (x_i - \\langle x \\rangle) (y_i - \\langle y \\rangle) \n",
    "= \\frac1N \\sum_{i=1}^N (x_i - \\langle x \\rangle) (\\beta_0 + \\beta_1 x_i + \\varepsilon_i - \\beta_0 - \\beta_1 \\langle x \\rangle - \\langle \\varepsilon \\rangle ) \n",
    "\\\\\n",
    "&\n",
    "\\phantom{\\sigma_{xy}}\n",
    "= \\frac1N \\sum_{i=1}^N (x_i - \\langle x \\rangle) \\{ \\beta_1 (x_i - \\langle x \\rangle) + \\varepsilon_i - \\langle \\varepsilon \\rangle ) \n",
    "\\\\\n",
    "&\n",
    "\\phantom{\\sigma_{xy}}\n",
    "= \\beta_1 \\cdot \\frac1N \\sum_{i=1}^N (x_i - \\langle x \\rangle)^2 \n",
    "+ \\frac1N \\sum_{i=1}^N (x_i - \\langle x \\rangle) (\\varepsilon_i - \\langle \\varepsilon \\rangle ) \n",
    "= \\beta_1 \\sigma_x^2 + \\sigma_{x\\varepsilon}\n",
    "\\\\\n",
    "&\n",
    "\\hat b_1 \n",
    "= \\frac{\\sigma_{xy}}{\\sigma_x^2} \n",
    "= \\frac{\\beta_1 \\sigma_x^2 + \\sigma_{x\\varepsilon}}{\\sigma_x^2}\n",
    "= \\beta_1 + \\frac{\\sigma_{x\\varepsilon}}{\\sigma_x^2}\n",
    "\\\\\n",
    "&\n",
    "\\mathrm E[\\hat b_1] = \\beta_1 + \\frac{\\mathrm E[\\sigma_{x\\varepsilon}]}{\\sigma_x^2}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "となる．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\varepsilon_i$ は同分布なので\n",
    "\n",
    "$$\n",
    "\\mathrm E \\left[ \\varepsilon_i - \\langle \\varepsilon \\rangle \\right]\n",
    "= \\mathrm E [ \\varepsilon_i] - \\frac1N \\sum_{j=1}^N \\mathrm E[\\varepsilon_j ]\n",
    "= \\mathrm E [ \\varepsilon] - \\frac1N \\sum_{j=1}^N \\mathrm E[\\varepsilon]\n",
    "= 0\n",
    "$$\n",
    "\n",
    "となるから，\n",
    "\n",
    "$$\n",
    "\\mathrm E[\\sigma_{x\\varepsilon}] \n",
    "= \\mathrm E \\left[ \\frac1N \\sum_{i=1}^N (x_i - \\langle x \\rangle) (\\varepsilon_i - \\langle \\varepsilon \\rangle ) \\right]\n",
    "= \\frac1N \\sum_{i=1}^N (x_i - \\langle x \\rangle) \\mathrm E \\left[ \\varepsilon_i - \\langle \\varepsilon \\rangle \\right]\n",
    "= 0\n",
    "$$\n",
    "\n",
    "したがって\n",
    "\n",
    "$$\n",
    "\\mathrm E[\\hat b_1] = \\beta_1 + \\frac{\\mathrm E[\\sigma_{x\\varepsilon}]}{\\sigma_x^2}\n",
    "= \\beta_1\n",
    "$$\n",
    "\n",
    "を得るので，データから推定されたパラメータ $\\hat b_1$ は真のパラメータ $\\beta_1$ の不偏推定量である．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "また， $\\hat b_1$ の分散は\n",
    "\n",
    "$$\n",
    "\\mathrm E[(\\hat b_1 - \\beta_1)^2] = \\frac{\\mathrm E[\\sigma_{x\\varepsilon}^2]}{\\sigma_x^4}\n",
    "$$\n",
    "\n",
    "である．$\\mathrm E[\\sigma_{x\\varepsilon}^2]$ を計算すると，\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "&\n",
    "\\mathrm E[\\sigma_{x\\varepsilon}^2] \n",
    "= \\mathrm E \\left[ \\frac1N \\sum_{i=1}^N (x_i - \\langle x \\rangle) (\\varepsilon_i - \\langle \\varepsilon \\rangle ) \\cdot \\frac1N \\sum_{j=1}^N (x_j - \\langle x \\rangle) (\\varepsilon_j - \\langle \\varepsilon \\rangle ) \\right]\n",
    "\\\\\n",
    "&\n",
    "\\phantom{\\mathrm E[\\sigma_{x\\varepsilon}^2]}\n",
    "= \\frac1{N^2} \\sum_{i=1}^N \\sum_{j=1}^N (x_i - \\langle x \\rangle) (x_j - \\langle x \\rangle) \\underbrace{\\mathrm E \\left[ (\\varepsilon_i - \\langle \\varepsilon \\rangle ) (\\varepsilon_j - \\langle \\varepsilon \\rangle ) \\right]}_{=\\mathrm{Cov}(\\varepsilon_i, \\varepsilon_j)}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "となる．$\\varepsilon_i$ $(i=1, 2, \\ldots, N)$ は互いに独立なので，\n",
    "\n",
    "- $i \\neq j$ ならば $\\mathrm{Cov}(\\varepsilon_i, \\varepsilon_j) = 0$\n",
    "- $i = j$ ならば $\\mathrm{Cov}(\\varepsilon_i, \\varepsilon_j) = \\mathrm V[\\varepsilon]$\n",
    "\n",
    "まとめると $\\mathrm{Cov}(\\varepsilon_i, \\varepsilon_j) = \\delta_{ij}\\mathrm{V}[\\varepsilon]$ ということ．$\\delta_{ij}$ はクロネッカーのデルタである．すると\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "&\n",
    "\\mathrm E[\\sigma_{x\\varepsilon}^2] \n",
    "= \\frac1{N^2} \\sum_{i=1}^N \\sum_{j=1}^N (x_i - \\langle x \\rangle) (x_j - \\langle x \\rangle) \\delta_{ij} \\mathrm V[\\varepsilon]\n",
    "= \\frac1{N^2} \\sum_{i=1}^N (x_i - \\langle x \\rangle)^2 \\mathrm V[\\varepsilon]\n",
    "\\\\\n",
    "&\n",
    "\\phantom{\\mathrm E[\\sigma_{x\\varepsilon}^2]}\n",
    "= \\frac1{N} \\sigma_x^2 \\mathrm V[\\varepsilon]\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "したがって\n",
    "\n",
    "$$\n",
    "\\mathrm E[(\\hat b_1 - \\beta_1)^2] = \\frac{\\mathrm E[\\sigma_{x\\varepsilon}^2]}{\\sigma_x^4}\n",
    "= \\frac{\\mathrm V[\\varepsilon]}{N\\sigma_x^2}\n",
    "$$\n",
    "\n",
    "独立同分布の標本平均の分散と同様に，データサイズが大きくなるにつれて推定されたパラメータ $\\hat b_1$ の分散は 0 に近づく．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\hat b_0$ の分布\n",
    "\n",
    "$\\hat b_0 = \\langle y \\rangle - \\hat b_1 \\langle x \\rangle$ であった．これに $\\langle y \\rangle$ の式を代入すると\n",
    "\n",
    "$$\n",
    "\\hat b_0 = \\langle y \\rangle - \\hat b_1 \\langle x \\rangle\n",
    "= \\beta_0 + \\beta_1 \\langle x \\rangle + \\langle \\varepsilon \\rangle - \\hat b_1 \\langle x \\rangle\n",
    "= \\beta_0 + (\\beta_1 - \\hat b_1) \\langle x \\rangle + \\langle \\varepsilon \\rangle\n",
    "$$\n",
    "\n",
    "となる．したがって\n",
    "\n",
    "$$\n",
    "\\mathrm E[\\hat b_0] = \\beta_0 + \\mathrm E[\\beta_1 - \\hat b_1] \\langle x \\rangle + \\mathrm E[\\langle \\varepsilon \\rangle]\n",
    "= \\beta_0 + 0 + 0 = \\beta_0\n",
    "$$\n",
    "\n",
    "$\\hat b_0$ も真のパラメータ $\\beta_0$ の不偏推定量となっている．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "また，$\\hat b_0$ の分散は\n",
    "\n",
    "$$\n",
    "\\mathrm E[(\\hat b_0 - \\beta_0)^2] \n",
    "= \\mathrm E[\\{(\\beta_1 - \\hat b_1) \\langle x \\rangle + \\langle \\varepsilon \\rangle\\}^2 ]\n",
    "= \\mathrm E[(\\beta_1 - \\hat b_1)^2] \\langle x \\rangle^2 \n",
    "+ 2 \\langle x \\rangle \\mathrm E[(\\beta_1 - \\hat b_1) \\langle \\varepsilon \\rangle]  \n",
    "+ \\mathrm E[\\langle \\varepsilon \\rangle^2]\n",
    "$$\n",
    "\n",
    "である．ここで\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "&\n",
    "\\mathrm E[(\\beta_1 - \\hat b_1) \\langle \\varepsilon \\rangle]  \n",
    "= -\\frac1{\\sigma_x^2} \\mathrm E[\\sigma_{x\\varepsilon}\\langle \\varepsilon \\rangle]  \n",
    "= -\\frac1{\\sigma_x^2} \\mathrm E \\left[ \\frac1N \\sum_{i=1}^N (x_i - \\langle x \\rangle) (\\varepsilon_i - \\langle \\varepsilon \\rangle) \\cdot \\frac1N \\sum_{j=1}^N \\varepsilon_j \\right]  \n",
    "\\\\\n",
    "&\n",
    "\\phantom{\\mathrm E[(\\beta_1 - \\hat b_1) \\langle \\varepsilon \\rangle]}\n",
    "= -\\frac1{N^2 \\sigma_x^2} \\sum_{i=1}^N \\sum_{j=1}^N (x_i - \\langle x \\rangle) \\mathrm E \\left[  (\\varepsilon_i - \\langle \\varepsilon \\rangle) \\cdot  \\varepsilon_j \\right]  \n",
    "= -\\frac1{N^2 \\sigma_x^2} \\sum_{i=1}^N \\sum_{j=1}^N (x_i - \\langle x \\rangle) \\left( \\mathrm{Cov}(\\varepsilon_i, \\varepsilon_j) - \\mathrm E \\left[ \\sum_{k=1}^N \\varepsilon_k \\varepsilon_j \\right] \\right)\n",
    "\\\\\n",
    "&\n",
    "\\phantom{\\mathrm E[(\\beta_1 - \\hat b_1) \\langle \\varepsilon \\rangle]}\n",
    "= -\\frac1{N^2 \\sigma_x^2} \\sum_{i=1}^N \\sum_{j=1}^N (x_i - \\langle x \\rangle) \\left( \\delta_{ij} \\mathrm{V}[\\varepsilon] - \\sum_{k=1}^N \\delta_{kj} \\mathrm V[\\varepsilon] \\right)\n",
    "\\\\\n",
    "&\n",
    "\\phantom{\\mathrm E[(\\beta_1 - \\hat b_1) \\langle \\varepsilon \\rangle]}\n",
    "= -\\frac1{N^2 \\sigma_x^2} \\left( \\sum_{i=1}^N (x_i - \\langle x \\rangle) \\mathrm{V}[\\varepsilon] - \\sum_{i=1}^N (x_i - \\langle x \\rangle) \\sum_{j=1}^N \\mathrm V[\\varepsilon] \\right)\n",
    "= 0\n",
    "\\\\\n",
    "&\n",
    "\\mathrm E[\\langle \\varepsilon \\rangle^2]\n",
    "= \\mathrm E \\left[ \\frac1N \\sum_{i=1}^N \\varepsilon_i \\cdot \\frac1N \\sum_{j=1}^N \\varepsilon_j \\right]\n",
    "= \\frac1N \\sum_{i=1}^N \\sum_{j=1}^N \\mathrm E \\left[ \\varepsilon_i \\varepsilon_j \\right]\n",
    "= \\frac1{N^2} \\sum_{i=1}^N \\sum_{j=1}^N \\delta_{ij} \\mathrm V [\\varepsilon]\n",
    "= \\frac1{N^2} \\sum_{i=1}^N \\mathrm V [\\varepsilon]\n",
    "= \\frac1N \\mathrm V [\\varepsilon]\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "したがって\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "&\n",
    "\\mathrm E[(\\hat b_0 - \\beta_0)^2] \n",
    "= \\frac{\\mathrm V[\\varepsilon]}{N\\sigma_x^2} \\langle x \\rangle^2\n",
    "+ 0\n",
    "+ \\frac1N \\mathrm V [\\varepsilon]\n",
    "= \\frac{\\langle x \\rangle^2 + \\sigma_x^2}{N\\sigma_x^2} \\mathrm V[\\varepsilon]\n",
    "= \\frac{\\langle x^2 \\rangle}{N\\sigma_x^2} \\mathrm V[\\varepsilon]\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "これも $\\hat b_1$ のときと同様に，データサイズが大きくなるにつれて $\\hat b_0$ の分散は 0 に近づく．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 演習問題 3-2\n",
    "\n",
    "線形単回帰であっても，対象のデータをきちんと観察することが大事だということを確認しよう．\n",
    "\n",
    "ここでは有名な Anscombe のデータを用いる．(Francis J. Anscombe, “Graphs in Statistical Analysis”, The American Statistician, Vol. 27, No. 1. (Feb., 1973), pp. 17-21.) \n",
    "\n",
    "４つのデータセットに対してそれぞれ，\n",
    "\n",
    "- 散布図\n",
    "- 個々のデータセットのsummary\n",
    "- 線形単回帰分析の結果の描画\n",
    "- 回帰係数，決定係数\n",
    "\n",
    "をまとめ，考察を与えよ．データセットの csv ファイルもクラスウェブに置いてある．\n",
    "\n",
    "演習問題は新規に notebook を立ち上げ，\n",
    "\n",
    "- 演習問題の番号\n",
    "- 氏名\n",
    "- 学生番号\n",
    "- 回答内容\n",
    "\n",
    "をセルにきちんと記載すること．\n",
    "\n",
    "回答内容は，code セルで計算し，図示するだけではなく，適宜 markdown セルで説明の記述を必ず行うこと．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x123</th>\n",
       "      <th>y1</th>\n",
       "      <th>y2</th>\n",
       "      <th>y3</th>\n",
       "      <th>x4</th>\n",
       "      <th>y4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>8.04</td>\n",
       "      <td>9.14</td>\n",
       "      <td>7.46</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.0</td>\n",
       "      <td>6.95</td>\n",
       "      <td>8.14</td>\n",
       "      <td>6.77</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.0</td>\n",
       "      <td>7.58</td>\n",
       "      <td>8.74</td>\n",
       "      <td>12.74</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.0</td>\n",
       "      <td>8.81</td>\n",
       "      <td>8.77</td>\n",
       "      <td>7.11</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.0</td>\n",
       "      <td>8.33</td>\n",
       "      <td>9.26</td>\n",
       "      <td>7.81</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14.0</td>\n",
       "      <td>9.96</td>\n",
       "      <td>8.10</td>\n",
       "      <td>8.84</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.0</td>\n",
       "      <td>7.24</td>\n",
       "      <td>6.13</td>\n",
       "      <td>6.08</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.26</td>\n",
       "      <td>3.10</td>\n",
       "      <td>5.39</td>\n",
       "      <td>19.0</td>\n",
       "      <td>12.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12.0</td>\n",
       "      <td>10.84</td>\n",
       "      <td>9.13</td>\n",
       "      <td>8.15</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7.0</td>\n",
       "      <td>4.82</td>\n",
       "      <td>7.26</td>\n",
       "      <td>6.42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.68</td>\n",
       "      <td>4.74</td>\n",
       "      <td>5.73</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    x123     y1    y2     y3    x4     y4\n",
       "0   10.0   8.04  9.14   7.46   8.0   6.58\n",
       "1    8.0   6.95  8.14   6.77   8.0   5.76\n",
       "2   13.0   7.58  8.74  12.74   8.0   7.71\n",
       "3    9.0   8.81  8.77   7.11   8.0   8.84\n",
       "4   11.0   8.33  9.26   7.81   8.0   8.47\n",
       "5   14.0   9.96  8.10   8.84   8.0   7.04\n",
       "6    6.0   7.24  6.13   6.08   8.0   5.25\n",
       "7    4.0   4.26  3.10   5.39  19.0  12.50\n",
       "8   12.0  10.84  9.13   8.15   8.0   5.56\n",
       "9    7.0   4.82  7.26   6.42   8.0   7.91\n",
       "10   5.0   5.68  4.74   5.73   8.0   6.89"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10.    8.04  9.14  7.46  8.    6.58]\n",
      " [ 8.    6.95  8.14  6.77  8.    5.76]\n",
      " [13.    7.58  8.74 12.74  8.    7.71]\n",
      " [ 9.    8.81  8.77  7.11  8.    8.84]\n",
      " [11.    8.33  9.26  7.81  8.    8.47]\n",
      " [14.    9.96  8.1   8.84  8.    7.04]\n",
      " [ 6.    7.24  6.13  6.08  8.    5.25]\n",
      " [ 4.    4.26  3.1   5.39 19.   12.5 ]\n",
      " [12.   10.84  9.13  8.15  8.    5.56]\n",
      " [ 7.    4.82  7.26  6.42  8.    7.91]\n",
      " [ 5.    5.68  4.74  5.73  8.    6.89]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x123</th>\n",
       "      <th>y1</th>\n",
       "      <th>y2</th>\n",
       "      <th>y3</th>\n",
       "      <th>x4</th>\n",
       "      <th>y4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>7.500909</td>\n",
       "      <td>7.500909</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>7.500909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.316625</td>\n",
       "      <td>2.031568</td>\n",
       "      <td>2.031657</td>\n",
       "      <td>2.030424</td>\n",
       "      <td>3.316625</td>\n",
       "      <td>2.030579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.260000</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>5.390000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.500000</td>\n",
       "      <td>6.315000</td>\n",
       "      <td>6.695000</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.170000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>7.580000</td>\n",
       "      <td>8.140000</td>\n",
       "      <td>7.110000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>7.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11.500000</td>\n",
       "      <td>8.570000</td>\n",
       "      <td>8.950000</td>\n",
       "      <td>7.980000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.190000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>14.000000</td>\n",
       "      <td>10.840000</td>\n",
       "      <td>9.260000</td>\n",
       "      <td>12.740000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>12.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            x123         y1         y2         y3         x4         y4\n",
       "count  11.000000  11.000000  11.000000  11.000000  11.000000  11.000000\n",
       "mean    9.000000   7.500909   7.500909   7.500000   9.000000   7.500909\n",
       "std     3.316625   2.031568   2.031657   2.030424   3.316625   2.030579\n",
       "min     4.000000   4.260000   3.100000   5.390000   8.000000   5.250000\n",
       "25%     6.500000   6.315000   6.695000   6.250000   8.000000   6.170000\n",
       "50%     9.000000   7.580000   8.140000   7.110000   8.000000   7.040000\n",
       "75%    11.500000   8.570000   8.950000   7.980000   8.000000   8.190000\n",
       "max    14.000000  10.840000   9.260000  12.740000  19.000000  12.500000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# csv読み込み\n",
    "df = pd.read_csv('data_Anscombe.csv')\n",
    "display(df)\n",
    "\n",
    "# numpy配列取り出し\n",
    "data = df.values\n",
    "print(data)\n",
    "\n",
    "# dataset1, 2, 3 の説明変数は第0列\n",
    "X123 = data[:, 0]\n",
    "\n",
    "# dataset1 の目的変数\n",
    "Y1 = data[:, 1]\n",
    "\n",
    "plt.scatter(X123, Y1)\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><div style=\"text-align: right;\">その3につづく</div></h3>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
